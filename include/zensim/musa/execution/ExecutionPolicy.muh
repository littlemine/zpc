#pragma once

#include <cooperative_groups.h>
#include <musa.h>

#include "zensim/execution/ExecutionPolicy.hpp"
#include "zensim/musa/Musa.h"
#include "zensim/types/Tuple.h"
// #include <device_types.h>
#include <iterator>
#include <type_traits>

#include "zensim/ZpcFunction.hpp"

#if ZS_ENABLE_MUSA && !defined(__MUSACC__)
#  error "ZS_ENABLE_MUSA defined but the compiler is not defining the __MUSACC__ macro as expected"
#  define __MUSACC__
#endif

namespace zs {

  namespace detail {

    template <typename F, typename ArgSeq, typename = void> struct deduce_fts {
      static constexpr bool fts_available
          = is_valid([](auto t) -> decltype(zs::function_traits<typename decltype(t)::type>{},
                                            void()) {})(zs::wrapt<F>{});

      template <typename IterOrIndex, typename = void> struct iter_arg {
        using type = IterOrIndex;
      };
      template <typename Iter> struct iter_arg<Iter, void_t<decltype(*declval<Iter>())>> {
        using type = decltype(*declval<Iter>());
      };
      template <typename IterOrIndex> using iter_arg_t = typename iter_arg<IterOrIndex>::type;

      template <typename Seq> struct impl;
      template <typename... Args> struct impl<type_seq<Args...>> {
        static constexpr auto deduce_args_t() noexcept {
          if constexpr (fts_available)
            return typename function_traits<F>::arguments_t{};
          else {
            if constexpr (is_invocable_v<F, int, iter_arg_t<Args>...>)
              return type_seq<int, iter_arg_t<Args>...>{};
            else if constexpr (is_invocable_v<F, void *, iter_arg_t<Args>...>)
              return type_seq<void *, iter_arg_t<Args>...>{};
            else
              return type_seq<iter_arg_t<Args>...>{};
          }
        }
        static constexpr auto deduce_return_t() noexcept {
          if constexpr (fts_available)
            return wrapt<typename function_traits<F>::return_t>{};
          else {
            if constexpr (is_invocable_v<F, int, iter_arg_t<Args>...>)
              return wrapt<invoke_result_t<F, int, iter_arg_t<Args>...>>{};
            else if constexpr (is_invocable_v<F, void *, iter_arg_t<Args>...>)
              return wrapt<invoke_result_t<F, void *, iter_arg_t<Args>...>>{};
            else
              return wrapt<invoke_result_t<F, iter_arg_t<Args>...>>{};
          }
        }
        static constexpr size_t deduce_arity() noexcept {
          if constexpr (fts_available)
            return function_traits<F>::arity;
          else
            return decltype(deduce_args_t())::count;
        }
      };

      using arguments_t =
          typename decltype(impl<ArgSeq>::deduce_args_t())::template functor<zs::tuple>;
      using first_argument_t = typename decltype(impl<ArgSeq>::deduce_args_t())::template type<0>;

      using return_t = typename decltype(impl<ArgSeq>::deduce_return_t())::type;
      static constexpr size_t arity = impl<ArgSeq>::deduce_arity();

      static_assert(is_same_v<return_t, void>,
                    "callable for execution policy should only return void");
    };
    template <typename F, typename ArgSeq, typename... Ts>
    struct deduce_fts<F, ArgSeq, zs::tuple<Ts...>> {
      using param_arg_t = zs::tuple<Ts...>;
      static constexpr bool fts_available
          = is_valid([](auto t) -> decltype(zs::function_traits<typename decltype(t)::type>{},
                                            void()) {})(zs::wrapt<F>{});

      template <typename IterOrIndex, typename = void> struct iter_arg {
        using type = IterOrIndex;
      };
      template <typename Iter> struct iter_arg<Iter, void_t<decltype(*declval<Iter>())>> {
        using type = decltype(*declval<Iter>());
      };
      template <typename IterOrIndex> using iter_arg_t = typename iter_arg<IterOrIndex>::type;

      template <typename Seq> struct impl;
      template <typename... Args> struct impl<type_seq<Args...>> {
        static constexpr auto deduce_args_t() noexcept {
          if constexpr (fts_available)
            return typename function_traits<F>::arguments_t{};
          else {
            if constexpr (is_invocable_v<F, int, iter_arg_t<Args>..., param_arg_t>)
              return type_seq<int, iter_arg_t<Args>..., param_arg_t>{};
            else if constexpr (is_invocable_v<F, void *, iter_arg_t<Args>..., param_arg_t>)
              return type_seq<void *, iter_arg_t<Args>..., param_arg_t>{};
            else
              return type_seq<iter_arg_t<Args>..., param_arg_t>{};
          }
        }
        static constexpr auto deduce_return_t() noexcept {
          if constexpr (fts_available)
            return wrapt<typename function_traits<F>::return_t>{};
          else {
            if constexpr (is_invocable_v<F, int, iter_arg_t<Args>..., param_arg_t>)
              return wrapt<invoke_result_t<F, int, iter_arg_t<Args>..., param_arg_t>>{};
            else if constexpr (is_invocable_v<F, void *, iter_arg_t<Args>..., param_arg_t>)
              return wrapt<invoke_result_t<F, void *, iter_arg_t<Args>..., param_arg_t>>{};
            else
              return wrapt<invoke_result_t<F, iter_arg_t<Args>..., param_arg_t>>{};
          }
        }
        static constexpr size_t deduce_arity() noexcept {
          if constexpr (fts_available)
            return function_traits<F>::arity;
          else
            return decltype(deduce_args_t())::count;
        }
      };

      using arguments_t =
          typename decltype(impl<ArgSeq>::deduce_args_t())::template functor<zs::tuple>;
      using first_argument_t = typename decltype(impl<ArgSeq>::deduce_args_t())::template type<0>;

      using return_t = typename decltype(impl<ArgSeq>::deduce_return_t())::type;
      static constexpr size_t arity = impl<ArgSeq>::deduce_arity();

      static_assert(is_same_v<return_t, void>,
                    "callable for execution policy should only return void");
    };

    template <bool withIndex, typename Tn, typename F, typename ZipIter, size_t... Is>
    __forceinline__ __device__ void range_foreach(wrapv<withIndex>, Tn i, F &&f, ZipIter &&iter,
                                                  index_sequence<Is...>) {
      (zs::get<Is>(iter.iters).advance(i), ...);
      if constexpr (withIndex)
        f(i, *zs::get<Is>(iter.iters)...);
      else {
        f(*zs::get<Is>(iter.iters)...);
      }
    }
    template <bool withIndex, typename ShmT, typename Tn, typename F, typename ZipIter,
              size_t... Is>
    __forceinline__ __device__ void range_foreach(wrapv<withIndex>, ShmT *shmem, Tn i, F &&f,
                                                  ZipIter &&iter, index_sequence<Is...>) {
      (zs::get<Is>(iter.iters).advance(i), ...);
      using func_traits
          = detail::deduce_fts<remove_cvref_t<F>, typename RM_REF_T(iter.iters)::tuple_types>;
      using shmem_ptr_t = typename func_traits::first_argument_t;
      if constexpr (withIndex)
        f(reinterpret_cast<shmem_ptr_t>(shmem), i, *zs::get<Is>(iter.iters)...);
      else
        f(reinterpret_cast<shmem_ptr_t>(shmem), *zs::get<Is>(iter.iters)...);
    }

    template <bool withIndex, typename Tn, typename F, typename ZipIter, typename ParamTuple,
              size_t... Is>
    __forceinline__ __device__ void range_foreach_with_params(wrapv<withIndex>, Tn i, F &&f,
                                                              ZipIter &&iter, ParamTuple &&params,
                                                              index_sequence<Is...>) {
      ((void)zs::get<Is>(iter.iters).advance(i), ...);
      if constexpr (withIndex)
        f(i, *zs::get<Is>(iter.iters)..., FWD(params));
      else {
        f(*zs::get<Is>(iter.iters)..., FWD(params));
      }
    }
    template <bool withIndex, typename ShmT, typename Tn, typename F, typename ZipIter,
              typename ParamTuple, size_t... Is>
    __forceinline__ __device__ void range_foreach_with_params(wrapv<withIndex>, ShmT *shmem, Tn i,
                                                              F &&f, ZipIter &&iter,
                                                              ParamTuple &&params,
                                                              index_sequence<Is...>) {
      ((void)zs::get<Is>(iter.iters).advance(i), ...);
      using func_traits
          = detail::deduce_fts<remove_cvref_t<F>, typename RM_REF_T(iter.iters)::tuple_types>;
      using shmem_ptr_t = typename func_traits::first_argument_t;
      if constexpr (withIndex)
        f(reinterpret_cast<shmem_ptr_t>(shmem), i, *zs::get<Is>(iter.iters)..., FWD(params));
      else
        f(reinterpret_cast<shmem_ptr_t>(shmem), *zs::get<Is>(iter.iters)..., FWD(params));
    }
  }  // namespace detail

  // =========================  signature  ==============================
  // loopbody signature: (scratchpadMemory, blockid, warpid, threadid)
  template <typename Tn, typename F> __global__ void thread_launch(Tn n, F f) {
    extern __shared__ std::max_align_t shmem[];
    Tn id = blockIdx.x * blockDim.x + threadIdx.x;
    if (id < n) {
      using func_traits = detail::deduce_fts<F, type_seq<RM_CVREF_T(id)>>;
      static_assert(func_traits::arity >= 1 && func_traits::arity <= 2,
                    "thread_launch requires arity to be within [1, 2]");
      if constexpr (func_traits::arity == 1)
        f(id);
      else if constexpr (func_traits::arity == 2) {
        static_assert(std::is_pointer_v<typename func_traits::first_argument_t>,
                      "the first argument must be a shmem pointer");
        f(reinterpret_cast<typename func_traits::first_argument_t>(shmem), id);
      }
    }
  }
  template <typename F> __global__ void block_thread_launch(F f) {
    extern __shared__ std::max_align_t shmem[];
    using func_traits
        = detail::deduce_fts<F, type_seq<RM_CVREF_T(blockIdx.x), RM_CVREF_T(threadIdx.x)>>;
    static_assert(func_traits::arity >= 2 && func_traits::arity <= 3,
                  "block_thread_launch requires arity to be within [2, 3]");
    if constexpr (func_traits::arity == 2) {
      static_assert(!std::is_pointer_v<typename func_traits::first_argument_t>,
                    "the first argument must NOT be a shmem pointer");
      f(blockIdx.x, threadIdx.x);
    } else if constexpr (func_traits::arity == 3) {
      static_assert(std::is_pointer_v<typename func_traits::first_argument_t>,
                    "the first argument must be a shmem pointer");
      f(reinterpret_cast<typename func_traits::first_argument_t>(shmem), blockIdx.x, threadIdx.x);
    }
  }

  template <typename Tn, typename F, typename ZipIter> __global__
      enable_if_type<is_ra_iter_v<ZipIter>
                     && (is_tuple<typename std::iterator_traits<ZipIter>::reference>::value
                         || is_std_tuple<typename std::iterator_traits<ZipIter>::reference>::value)>
      range_launch(Tn n, F f, ZipIter iter) {
    extern __shared__ std::max_align_t shmem[];
    Tn id = blockIdx.x * blockDim.x + threadIdx.x;
    if (id < n) {
      using func_traits = detail::deduce_fts<F, typename RM_REF_T(iter.iters)::tuple_types>;
      constexpr auto numArgs = zs::tuple_size_v<typename std::iterator_traits<ZipIter>::reference>;
      constexpr auto indices = make_index_sequence<numArgs>{};
      static_assert(func_traits::arity >= numArgs && func_traits::arity <= numArgs + 2,
                    "range_launch arity does not match with numArgs");
      if constexpr (func_traits::arity == numArgs) {
        detail::range_foreach(false_c, id, f, iter, indices);
      } else if constexpr (func_traits::arity == numArgs + 1) {
        static_assert(
            is_integral_v<typename func_traits::first_argument_t>
                || is_pointer_v<typename func_traits::first_argument_t>,
            "when arity equals numArgs+1, the first argument should be a shmem pointer or an "
            "integer");
        if constexpr (is_integral_v<typename func_traits::first_argument_t>)
          detail::range_foreach(true_c, id, f, iter, indices);
        else if constexpr (is_pointer_v<typename func_traits::first_argument_t>)
          detail::range_foreach(false_c,
                                reinterpret_cast<typename func_traits::first_argument_t>(shmem), id,
                                f, iter, indices);
      } else if constexpr (func_traits::arity == numArgs + 2) {
        static_assert(is_pointer_v<typename func_traits::first_argument_t>,
                      "when arity equals numArgs+2, the first argument should be a shmem pointer");
        detail::range_foreach(true_c,
                              reinterpret_cast<typename func_traits::first_argument_t>(shmem), id,
                              f, iter, indices);
      }
    }
  }
  template <typename Tn, typename F, typename ZipIter, typename... Args> __global__
      enable_if_type<is_ra_iter_v<ZipIter>
                     && (is_tuple<typename std::iterator_traits<ZipIter>::reference>::value
                         || is_std_tuple<typename std::iterator_traits<ZipIter>::reference>::value)>
      range_launch_with_params(Tn n, F f, ZipIter iter, zs::tuple<Args...> params) {
    extern __shared__ std::max_align_t shmem[];
    Tn id = blockIdx.x * blockDim.x + threadIdx.x;
    if (id < n) {
      /// @note beware of the discrepency here
      using func_traits
          = detail::deduce_fts<F, typename RM_REF_T(iter.iters)::tuple_types, zs::tuple<Args...>>;
      constexpr auto numArgs
          = zs::tuple_size_v<typename std::iterator_traits<ZipIter>::reference> + 1;
      constexpr auto indices = make_index_sequence<numArgs - 1>{};

      static_assert(func_traits::arity >= numArgs && func_traits::arity <= numArgs + 2,
                    "range_launch_with_params arity does not match with numArgs");
      if constexpr (func_traits::arity == numArgs) {
        detail::range_foreach_with_params(false_c, id, f, iter, params, indices);
      } else if constexpr (func_traits::arity == numArgs + 1) {
        static_assert(is_integral_v<typename func_traits::first_argument_t>
                          || is_pointer_v<typename func_traits::first_argument_t>,
                      "when arity equals numArgs+1 (tail for params), the first argument should be "
                      "a shmem pointer or an integer");
        if constexpr (is_integral_v<typename func_traits::first_argument_t>)
          detail::range_foreach_with_params(true_c, id, f, iter, params, indices);
        else if constexpr (is_pointer_v<typename func_traits::first_argument_t>)
          detail::range_foreach_with_params(
              false_c, reinterpret_cast<typename func_traits::first_argument_t>(shmem), id, f, iter,
              params, indices);
        else
          static_assert(always_false<Tn>, "slot reserved...");
      } else if constexpr (func_traits::arity == numArgs + 2) {
        static_assert(is_pointer_v<typename func_traits::first_argument_t>,
                      "when arity equals numArgs+2 (tail for params), the first argument should be "
                      "a shmem pointer");
        detail::range_foreach_with_params(
            true_c, reinterpret_cast<typename func_traits::first_argument_t>(shmem), id, f, iter,
            params, indices);
      }
    }
  }

  namespace cg = cooperative_groups;
  template <typename Tn, typename F> __global__ void block_tile_lane_launch(Tn tileSize, F f) {
    extern __shared__ std::max_align_t shmem[];
    cg::thread_block block = cg::this_thread_block();
    cg::thread_group tile = cg::tiled_partition(block, tileSize);
    using func_traits = detail::deduce_fts<
        F, type_seq<RM_CVREF_T(blockIdx.x), RM_CVREF_T(block.thread_rank() / tileSize),
                    RM_CVREF_T(tile.thread_rank())>>;
    static_assert(func_traits::arity >= 3 && func_traits::arity <= 4,
                  "block_tile_lane_launch requires arity to be within [3, 4]");
    if constexpr (func_traits::arity == 3) {
      static_assert(!std::is_pointer_v<typename func_traits::first_argument_t>,
                    "the first argument must NOT be a shmem pointer");
      f(blockIdx.x, block.thread_rank() / tileSize, tile.thread_rank());
    } else if constexpr (func_traits::arity == 4) {
      static_assert(std::is_pointer_v<typename func_traits::first_argument_t>,
                    "the first argument must be a shmem pointer");
      f(reinterpret_cast<typename func_traits::first_argument_t>(shmem), blockIdx.x,
        block.thread_rank() / tileSize, tile.thread_rank());
    }
  }

  struct MusaExecutionPolicy;
  ZPC_API extern ZSPmrAllocator<> get_temporary_memory_source(const MusaExecutionPolicy &pol);

  struct MusaExecutionPolicy : ExecutionPolicyInterface<MusaExecutionPolicy> {
    using exec_tag = musa_exec_tag;
    MusaExecutionPolicy &listen(ProcID incProc, StreamID incStream) {
      this->_wait = true;
      incomingProc = incProc;
      incomingStreamid = incStream;
      return *this;
    }
    MusaExecutionPolicy &stream(StreamID streamid_) {
      streamid = streamid_;
      return *this;
    }
    MusaExecutionPolicy &device(ProcID pid) {
      procid = pid;
      return *this;
    }
    MusaExecutionPolicy &shmem(size_t bytes) {
      shmemBytes = bytes;
      return *this;
    }
    MusaExecutionPolicy &block(size_t tpb) {
      blockSize = tpb;
      return *this;
    }

    void syncCtx(const source_location &loc = source_location::current()) const {
      auto &context = Musa::context(getProcid());
      context.syncStreamSpare(streamid, loc);
    }

    template <typename Ts, typename Is, typename F>
    void operator()(Collapse<Ts, Is> dims, F &&f,
                    const source_location &loc = source_location::current()) const {
      using namespace index_literals;
      constexpr auto dim = Collapse<Ts, Is>::dim;
      auto &context = Musa::context(getProcid());
      context.setContext();
      if (this->shouldWait())
        context.spareStreamWaitForEvent(streamid,
                                        Musa::context(incomingProc).eventSpare(incomingStreamid));
      Musa::MusaContext::StreamExecutionTimer *timer{};
      if (this->shouldProfile()) timer = context.tick(context.streamSpare(streamid), loc);

      // need to work on __device__ func as well
      u32 ec = 0;
      if constexpr (dim == 1) {
        LaunchConfig lc{};
        if (blockSize == 0)
          lc = LaunchConfig{true_c, dims.get(0_th), shmemBytes};
        else
          lc = LaunchConfig{(dims.get(0_th) + blockSize - 1) / blockSize, blockSize, shmemBytes};
        ec = musa_safe_launch(loc, context, streamid, std::move(lc), thread_launch, dims.get(0_th),
                              f);
      }
      // else if constexpr (arity == 2)
      else if constexpr (dim == 2) {
        ec = musa_safe_launch(loc, context, streamid, {dims.get(0_th), dims.get(1_th), shmemBytes},
                              block_thread_launch, f);
      }
      // else if constexpr (arity == 3)
      else if constexpr (dim == 3) {
        ec = musa_safe_launch(loc, context, streamid,
                              {dims.get(0_th), dims.get(1_th) * dims.get(2_th), shmemBytes},
                              block_tile_lane_launch, dims.get(2_th), f);
      }
      static_assert(dim >= 1 && dim <= 3,
                    "launch dimensions other than 1, 2, 3 are not supported yet");
      if (this->shouldProfile()) context.tock(timer, loc);
      if (this->shouldSync()) {
        context.syncStreamSpare(streamid, loc);
#if ZS_ENABLE_OFB_ACCESS_CHECK
        if (ec == 0) ec = Musa::get_last_musa_rt_error();
#endif
      }
      checkMuKernelLaunchError(ec, context, fmt::format("Spare [{}]", streamid), loc);
      context.recordEventSpare(streamid, loc);
    }
    template <typename Range, typename F>
    auto operator()(Range &&range, F &&f,
                    const source_location &loc = source_location::current()) const {
      auto &context = Musa::context(getProcid());
      context.setContext();
      if (this->shouldWait())
        context.spareStreamWaitForEvent(streamid,
                                        Musa::context(incomingProc).eventSpare(incomingStreamid));

      // need to work on __device__ func as well
      auto iter = std::begin(range);
      using IterT = remove_cvref_t<decltype(iter)>;
      using DiffT = typename std::iterator_traits<IterT>::difference_type;
      const DiffT dist = std::end(range) - iter;
      using RefT = typename std::iterator_traits<IterT>::reference;

      LaunchConfig lc{};
      if (blockSize == 0)
        lc = LaunchConfig{true_c, dist, shmemBytes};
      else
        lc = LaunchConfig{(dist + blockSize - 1) / blockSize, blockSize, shmemBytes};

      Musa::MusaContext::StreamExecutionTimer *timer{};
      if (this->shouldProfile()) timer = context.tick(context.streamSpare(streamid), loc);

      u32 ec = 0;
      if constexpr (is_zip_iterator_v<IterT>) {
        ec = musa_safe_launch(loc, context, streamid, std::move(lc), range_launch, dist, f,
                              std::begin(FWD(range)));
      } else {  // wrap the non-zip range in a zip range
        ec = musa_safe_launch(loc, context, streamid, std::move(lc), range_launch, dist, f,
                              std::begin(zip(FWD(range))));
      }

      if (this->shouldProfile()) context.tock(timer, loc);
      if (this->shouldSync()) {
        context.syncStreamSpare(streamid, loc);
#if ZS_ENABLE_OFB_ACCESS_CHECK
        if (ec == 0) ec = Musa::get_last_musa_rt_error();
#endif
      }
      checkMuKernelLaunchError(ec, context, fmt::format("Spare [{}]", streamid), loc);
      context.recordEventSpare(streamid, loc);
    }
    template <typename Range, typename... Args, typename F>
    auto operator()(Range &&range, const zs::tuple<Args...> &params, F &&f,
                    const source_location &loc = source_location::current()) const {
      auto &context = Musa::context(getProcid());
      context.setContext();
      if (this->shouldWait())
        context.spareStreamWaitForEvent(streamid,
                                        Musa::context(incomingProc).eventSpare(incomingStreamid));

      // need to work on __device__ func as well
      auto iter = std::begin(range);
      using IterT = remove_cvref_t<decltype(iter)>;
      using DiffT = typename std::iterator_traits<IterT>::difference_type;
      const DiffT dist = std::end(range) - iter;
      using RefT = typename std::iterator_traits<IterT>::reference;

      LaunchConfig lc{};
      if (blockSize == 0)
        lc = LaunchConfig{true_c, dist, shmemBytes};
      else
        lc = LaunchConfig{(dist + blockSize - 1) / blockSize, blockSize, shmemBytes};

      Musa::MusaContext::StreamExecutionTimer *timer{};
      if (this->shouldProfile()) timer = context.tick(context.streamSpare(streamid), loc);

      u32 ec = 0;
      if constexpr (is_zip_iterator_v<IterT>) {
        ec = musa_safe_launch(loc, context, streamid, std::move(lc), range_launch_with_params, dist,
                              f, std::begin(FWD(range)), params);
      } else {  // wrap the non-zip range in a zip range
        ec = musa_safe_launch(loc, context, streamid, std::move(lc), range_launch_with_params, dist,
                              f, std::begin(zip(FWD(range))), params);
      }

      if (this->shouldProfile()) context.tock(timer, loc);
      if (this->shouldSync()) {
        context.syncStreamSpare(streamid, loc);
#if ZS_ENABLE_OFB_ACCESS_CHECK
        if (ec == 0) ec = Musa::get_last_musa_rt_error();
#endif
      }
      checkMuKernelLaunchError(ec, context, fmt::format("Spare [{}]", streamid), loc);
      context.recordEventSpare(streamid, loc);
    }

    /// for_each
    template <class ForwardIt, class UnaryFunction>
    void for_each_impl(std::random_access_iterator_tag, ForwardIt &&first, ForwardIt &&last,
                       UnaryFunction &&f, const source_location &loc) const {
      using IterT = remove_cvref_t<ForwardIt>;
      const auto dist = last - first;
      (*this)(
          Collapse{dist},
          [first = FWD(first), f = FWD(f)] __device__(
              typename std::iterator_traits<IterT>::difference_type tid) mutable {
            f(*(first + tid));
          },
          loc);
    }
    template <class ForwardIt, class UnaryFunction>
    void for_each(ForwardIt &&first, ForwardIt &&last, UnaryFunction &&f,
                  const source_location &loc = source_location::current()) const {
      static_assert(is_ra_iter_v<remove_cvref_t<ForwardIt>>,
                    "Iterator should be a random access iterator");
      for_each_impl(std::random_access_iterator_tag{}, FWD(first), FWD(last), FWD(f), loc);
    }

    constexpr ProcID getProcid() const noexcept {
      if (procid < 0) return Musa::get_default_device();
      return procid;
    }
    constexpr StreamID getStreamid() const noexcept { return streamid; }
    void *getStream() const noexcept {
      return Musa::context(getProcid()).streamSpare(getStreamid());
    }
    decltype(auto) context() { return Musa::context(getProcid()); }
    decltype(auto) context() const { return Musa::context(getProcid()); }
    void *getContext() const { return context().getContext(); }

    constexpr ProcID getIncomingProcid() const noexcept { return incomingProc; }
    constexpr StreamID getIncomingStreamid() const noexcept { return incomingStreamid; }

    constexpr size_t getShmemSize() const noexcept { return shmemBytes; }

  protected:
    // bool do_launch(const ParallelTask &) const noexcept;
    friend struct ExecutionPolicyInterface<MusaExecutionPolicy>;
    // template <auto flagbit> friend struct CudaLibHandle<flagbit>;

    // size_t blockGranularity{128};
    StreamID incomingStreamid{-1};
    StreamID streamid{-1};  ///< @note use CUDA default stream by default
    size_t shmemBytes{0};   ///< amount of shared memory passed
    int blockSize{0};       ///< 0 to enable auto configure
    ProcID incomingProc{0};
    ProcID procid{-1};  ///< use current default CUDA device
  };

}  // namespace zs